{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython.display as ipd\n",
    "\n",
    "for filename in os.listdir('./test_audio'):\n",
    "    ipd.Audio('./test_audio/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "for filename in os.listdir('./test'):\n",
    "    data, sampling_rate = librosa.load('./test/' + filename)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = sr.AudioFile('0_jackson_2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zero as source:\n",
    "    audio = r.record(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.recognize_google(audio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the main training part:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training with audio files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#imports:\n",
    "\n",
    "from export_model import *\n",
    "from preprocess import *\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors of label - '1': 100%|█████████████████████████████████████████████████| 312/312 [00:03<00:00, 79.11it/s]\n",
      "Saving vectors of label - '10': 100%|████████████████████████████████████████████████| 143/143 [00:02<00:00, 58.97it/s]\n",
      "Saving vectors of label - '11': 100%|████████████████████████████████████████████████| 137/137 [00:02<00:00, 54.71it/s]\n",
      "Saving vectors of label - '12': 100%|████████████████████████████████████████████████| 132/132 [00:02<00:00, 51.85it/s]\n",
      "Saving vectors of label - '2': 100%|█████████████████████████████████████████████████| 272/272 [00:05<00:00, 52.59it/s]\n",
      "Saving vectors of label - '3': 100%|█████████████████████████████████████████████████| 250/250 [00:04<00:00, 62.62it/s]\n",
      "Saving vectors of label - '4': 100%|█████████████████████████████████████████████████| 139/139 [00:02<00:00, 54.60it/s]\n",
      "Saving vectors of label - '5': 100%|█████████████████████████████████████████████████| 166/166 [00:02<00:00, 57.62it/s]\n",
      "Saving vectors of label - '6': 100%|█████████████████████████████████████████████████| 145/145 [00:02<00:00, 54.74it/s]\n",
      "Saving vectors of label - '7': 100%|█████████████████████████████████████████████████| 150/150 [00:02<00:00, 51.40it/s]\n",
      "Saving vectors of label - '8': 100%|█████████████████████████████████████████████████| 154/154 [00:03<00:00, 48.41it/s]\n",
      "Saving vectors of label - '9': 100%|█████████████████████████████████████████████████| 139/139 [00:03<00:00, 44.55it/s]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#from preprocess import *\n",
    "#import keras\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "#from keras.utils import to_categorical\n",
    "#from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#import itertools\n",
    "\n",
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 11\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=feature_dim_2)\n",
    "\n",
    "# # Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "\n",
    "# # Feature dimension\n",
    "#defaults at the end\n",
    "feature_dim_1 = 20   #20\n",
    "channel = 1          #1\n",
    "epochs = 50         #50\n",
    "batch_size = 100     #100\n",
    "verbose = 1          #1\n",
    "# change num_classes depending on the amount of labels\n",
    "num_classes = 12\n",
    "\n",
    "# Reshaping to perform 2D convolution\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model & prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Predicts one sample\n",
    "def predict(filepath, model):\n",
    "    sample = wav2mfcc(filepath)\n",
    "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    return get_labels()[0][\n",
    "            np.argmax(model.predict(sample_reshaped))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "history = model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export current model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export_model(model)\n",
    "\n",
    "y_predicted = model.predict_classes(X_test, batch_size=batch_size)\n",
    "y_true_val = np.argmax(y_test_hot,axis=1)\n",
    "\n",
    "class_rep = classification_report(y_true_val,y_predicted,digits=5)\n",
    "\n",
    "settings = {\n",
    "    \"feature_dim_1\": feature_dim_1,\n",
    "    \"feature_dim_2\": feature_dim_2,\n",
    "    \"channel\": channel,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"train_accuracy\": str(history.history.get('acc')[-1]),\n",
    "    \"test_accuracy\": str(history.history.get('val_acc')[-1]),\n",
    "    \"train_loss\": str(history.history.get('loss')[-1]),\n",
    "    \"test_loss\": str(history.history.get('val_loss')[-1]),\n",
    "    \"classification_report\": class_rep\n",
    "}\n",
    "\n",
    "export_model(model, settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import_model(PATH)\n",
    "imported_model = import_model(\"./models/xxx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on a new file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(predict('./test_audio/12.wav', model=model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on a folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = './test_audio/'\n",
    "\n",
    "for filename in os.listdir(FOLDER_PATH):\n",
    "    pred = predict(FOLDER_PATH + filename, model=model)\n",
    "    print(filename + \" was predicted as: \" + pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy / Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Accuracy plot\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#Loss plot\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full report with confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#should import labels directly from folder:\n",
    "labels, _, _= get_labels(\"./audio\")\n",
    "labArray = []\n",
    "for label in labels:\n",
    "    labArray.append(label)\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit_transform(labArray)\n",
    "\n",
    "full_multiclass_report(model, X_test, y_test_hot, classes=le.inverse_transform(np.arange(12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for all the metrics and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title='Normalized confusion matrix'\n",
    "    else:\n",
    "        title='Confusion matrix'\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "def full_multiclass_report(model,\n",
    "                           x,\n",
    "                           y_true,\n",
    "                           classes,\n",
    "                           batch_size=32,\n",
    "                           binary=False):\n",
    "\n",
    "    # 1. Transform one-hot encoded y_true into their class number\n",
    "    if not binary:\n",
    "        y_true = np.argmax(y_true,axis=1)\n",
    "    \n",
    "    # 2. Predict classes and stores in y_pred\n",
    "    y_pred = model.predict_classes(x, batch_size=batch_size)\n",
    "    \n",
    "    # 3. Print accuracy score\n",
    "    print(\"Accuracy : \"+ str(accuracy_score(y_true,y_pred)))\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    # 4. Print classification report\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_true,y_pred,digits=5))    \n",
    "    \n",
    "    # 5. Plot confusion matrix\n",
    "    cnf_matrix = confusion_matrix(y_true,y_pred)\n",
    "    print(cnf_matrix)\n",
    "    plot_confusion_matrix(cnf_matrix,classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
