{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython.display as ipd\n",
    "\n",
    "for filename in os.listdir('./test'):\n",
    "    ipd.Audio('./test/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "for filename in os.listdir('./test'):\n",
    "    data, sampling_rate = librosa.load('./test/' + filename)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = sr.AudioFile('0_jackson_2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zero as source:\n",
    "    audio = r.record(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.recognize_google(audio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the main training part:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training with audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors of label - '1': 100%|███████████████████████████████████████████████████| 49/49 [00:00<00:00, 90.52it/s]\n",
      "Saving vectors of label - '2': 100%|███████████████████████████████████████████████████| 48/48 [00:00<00:00, 86.21it/s]\n",
      "Saving vectors of label - '3': 100%|███████████████████████████████████████████████████| 50/50 [00:00<00:00, 86.71it/s]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 11\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=feature_dim_2)\n",
    "\n",
    "# # Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "\n",
    "# # Feature dimension\n",
    "feature_dim_1 = 20\n",
    "channel = 1\n",
    "epochs = 50\n",
    "batch_size = 100\n",
    "verbose = 1\n",
    "num_classes = 3\n",
    "\n",
    "# Reshaping to perform 2D convolution\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model & prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Predicts one sample\n",
    "def predict(filepath, model):\n",
    "    sample = wav2mfcc(filepath)\n",
    "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    return get_labels()[0][\n",
    "            np.argmax(model.predict(sample_reshaped))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 88 samples, validate on 59 samples\n",
      "Epoch 1/100\n",
      "88/88 [==============================] - ETA: 3s - loss: 4.8838 - acc: 0.333 - ETA: 1s - loss: 5.5576 - acc: 0.266 - ETA: 0s - loss: 6.7225 - acc: 0.266 - ETA: 0s - loss: 7.0968 - acc: 0.266 - ETA: 0s - loss: 7.5254 - acc: 0.253 - 1s 15ms/step - loss: 7.3909 - acc: 0.2614 - val_loss: 1.6124 - val_acc: 0.4068\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 3.2988 - acc: 0.400 - ETA: 0s - loss: 3.8586 - acc: 0.400 - ETA: 0s - loss: 3.0384 - acc: 0.450 - ETA: 0s - loss: 2.7663 - acc: 0.440 - 0s 4ms/step - loss: 2.8242 - acc: 0.3977 - val_loss: 1.1599 - val_acc: 0.2881\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.7212 - acc: 0.400 - ETA: 0s - loss: 1.5430 - acc: 0.433 - ETA: 0s - loss: 1.4911 - acc: 0.377 - ETA: 0s - loss: 1.7612 - acc: 0.350 - ETA: 0s - loss: 1.7412 - acc: 0.346 - 0s 4ms/step - loss: 1.7164 - acc: 0.3409 - val_loss: 1.1323 - val_acc: 0.3390\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.3285 - acc: 0.333 - ETA: 0s - loss: 1.2346 - acc: 0.333 - ETA: 0s - loss: 1.1422 - acc: 0.377 - ETA: 0s - loss: 1.1824 - acc: 0.333 - 0s 4ms/step - loss: 1.1776 - acc: 0.3409 - val_loss: 1.1955 - val_acc: 0.3220\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.1224 - acc: 0.466 - ETA: 0s - loss: 1.2811 - acc: 0.366 - ETA: 0s - loss: 1.1602 - acc: 0.400 - ETA: 0s - loss: 1.1383 - acc: 0.386 - 0s 4ms/step - loss: 1.1279 - acc: 0.4091 - val_loss: 1.2664 - val_acc: 0.3220\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.2498 - acc: 0.466 - ETA: 0s - loss: 1.1830 - acc: 0.466 - ETA: 0s - loss: 1.2853 - acc: 0.346 - 0s 3ms/step - loss: 1.2739 - acc: 0.3409 - val_loss: 1.1439 - val_acc: 0.3051\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.9399 - acc: 0.466 - ETA: 0s - loss: 1.1642 - acc: 0.377 - ETA: 0s - loss: 1.1213 - acc: 0.400 - 0s 3ms/step - loss: 1.1427 - acc: 0.4091 - val_loss: 1.2708 - val_acc: 0.2881\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.6017 - acc: 0.200 - ETA: 0s - loss: 1.2690 - acc: 0.366 - ETA: 0s - loss: 1.2149 - acc: 0.350 - 0s 3ms/step - loss: 1.2097 - acc: 0.3523 - val_loss: 1.0954 - val_acc: 0.3051\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.0457 - acc: 0.466 - ETA: 0s - loss: 1.0737 - acc: 0.377 - ETA: 0s - loss: 1.0848 - acc: 0.366 - 0s 3ms/step - loss: 1.0847 - acc: 0.3750 - val_loss: 1.1471 - val_acc: 0.2881\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.2546 - acc: 0.133 - ETA: 0s - loss: 1.1015 - acc: 0.355 - ETA: 0s - loss: 1.1047 - acc: 0.333 - 0s 3ms/step - loss: 1.1634 - acc: 0.3295 - val_loss: 1.1084 - val_acc: 0.2881\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.0414 - acc: 0.400 - ETA: 0s - loss: 1.0834 - acc: 0.400 - ETA: 0s - loss: 1.0895 - acc: 0.383 - ETA: 0s - loss: 1.0625 - acc: 0.386 - 0s 4ms/step - loss: 1.0638 - acc: 0.3636 - val_loss: 1.1590 - val_acc: 0.2881\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.1059 - acc: 0.400 - ETA: 0s - loss: 1.2010 - acc: 0.311 - ETA: 0s - loss: 1.1629 - acc: 0.306 - 0s 3ms/step - loss: 1.1437 - acc: 0.2955 - val_loss: 1.0953 - val_acc: 0.4068\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.9717 - acc: 0.533 - ETA: 0s - loss: 1.0594 - acc: 0.466 - ETA: 0s - loss: 1.0412 - acc: 0.480 - 0s 3ms/step - loss: 1.0670 - acc: 0.4659 - val_loss: 1.1055 - val_acc: 0.3390\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.9496 - acc: 0.600 - ETA: 0s - loss: 1.0208 - acc: 0.466 - ETA: 0s - loss: 1.0392 - acc: 0.413 - 0s 3ms/step - loss: 1.0584 - acc: 0.3977 - val_loss: 1.1242 - val_acc: 0.3051\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.0106 - acc: 0.533 - ETA: 0s - loss: 1.0332 - acc: 0.466 - ETA: 0s - loss: 1.0450 - acc: 0.483 - ETA: 0s - loss: 1.0136 - acc: 0.493 - 0s 4ms/step - loss: 1.0419 - acc: 0.4773 - val_loss: 1.1239 - val_acc: 0.2881\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.0822 - acc: 0.400 - ETA: 0s - loss: 1.0641 - acc: 0.433 - ETA: 0s - loss: 1.0460 - acc: 0.433 - ETA: 0s - loss: 1.0499 - acc: 0.413 - 0s 4ms/step - loss: 1.0463 - acc: 0.4091 - val_loss: 1.1236 - val_acc: 0.3220\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.0441 - acc: 0.466 - ETA: 0s - loss: 0.9984 - acc: 0.577 - ETA: 0s - loss: 1.0110 - acc: 0.520 - 0s 3ms/step - loss: 1.0731 - acc: 0.4773 - val_loss: 1.1487 - val_acc: 0.4237\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.1880 - acc: 0.400 - ETA: 0s - loss: 1.1049 - acc: 0.355 - ETA: 0s - loss: 1.1000 - acc: 0.360 - 0s 3ms/step - loss: 1.0863 - acc: 0.3750 - val_loss: 1.1600 - val_acc: 0.3051\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.9483 - acc: 0.466 - ETA: 0s - loss: 1.0176 - acc: 0.500 - ETA: 0s - loss: 1.0791 - acc: 0.377 - ETA: 0s - loss: 1.1189 - acc: 0.350 - ETA: 0s - loss: 1.0974 - acc: 0.400 - 0s 4ms/step - loss: 1.0718 - acc: 0.3977 - val_loss: 1.1647 - val_acc: 0.2881\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.9781 - acc: 0.666 - ETA: 0s - loss: 1.0152 - acc: 0.533 - ETA: 0s - loss: 0.9609 - acc: 0.511 - ETA: 0s - loss: 0.9719 - acc: 0.516 - 0s 4ms/step - loss: 1.0519 - acc: 0.4773 - val_loss: 1.2000 - val_acc: 0.3220\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.0955 - acc: 0.400 - ETA: 0s - loss: 1.0186 - acc: 0.433 - ETA: 0s - loss: 0.9900 - acc: 0.488 - ETA: 0s - loss: 1.0445 - acc: 0.466 - 0s 4ms/step - loss: 1.0943 - acc: 0.4205 - val_loss: 1.1652 - val_acc: 0.2203\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.0658 - acc: 0.266 - ETA: 0s - loss: 1.0426 - acc: 0.266 - ETA: 0s - loss: 1.1027 - acc: 0.288 - ETA: 0s - loss: 1.0935 - acc: 0.333 - ETA: 0s - loss: 1.0980 - acc: 0.320 - 0s 4ms/step - loss: 1.0893 - acc: 0.3182 - val_loss: 1.1618 - val_acc: 0.2542\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.9825 - acc: 0.533 - ETA: 0s - loss: 0.9703 - acc: 0.600 - ETA: 0s - loss: 0.9881 - acc: 0.533 - 0s 3ms/step - loss: 1.0124 - acc: 0.4773 - val_loss: 1.1835 - val_acc: 0.3051\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.1961 - acc: 0.333 - ETA: 0s - loss: 1.1281 - acc: 0.333 - ETA: 0s - loss: 1.0205 - acc: 0.483 - 0s 3ms/step - loss: 1.0030 - acc: 0.5000 - val_loss: 1.1790 - val_acc: 0.3559\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.9483 - acc: 0.600 - ETA: 0s - loss: 1.0625 - acc: 0.500 - ETA: 0s - loss: 1.0321 - acc: 0.488 - ETA: 0s - loss: 0.9806 - acc: 0.520 - 0s 3ms/step - loss: 0.9609 - acc: 0.5455 - val_loss: 1.2231 - val_acc: 0.2881\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.2326 - acc: 0.333 - ETA: 0s - loss: 1.0117 - acc: 0.466 - ETA: 0s - loss: 0.9551 - acc: 0.520 - 0s 3ms/step - loss: 0.9484 - acc: 0.5341 - val_loss: 1.2025 - val_acc: 0.2881\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.9084 - acc: 0.533 - ETA: 0s - loss: 0.8809 - acc: 0.566 - ETA: 0s - loss: 0.9126 - acc: 0.500 - 0s 3ms/step - loss: 0.9352 - acc: 0.5114 - val_loss: 1.2651 - val_acc: 0.3051\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.8519 - acc: 0.466 - ETA: 0s - loss: 0.9191 - acc: 0.511 - ETA: 0s - loss: 0.9054 - acc: 0.600 - 0s 3ms/step - loss: 0.8939 - acc: 0.6023 - val_loss: 1.2743 - val_acc: 0.3390\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.7248 - acc: 0.800 - ETA: 0s - loss: 0.7248 - acc: 0.755 - ETA: 0s - loss: 0.8113 - acc: 0.693 - 0s 3ms/step - loss: 0.8296 - acc: 0.6591 - val_loss: 1.2728 - val_acc: 0.3898\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.9144 - acc: 0.666 - ETA: 0s - loss: 0.7757 - acc: 0.733 - ETA: 0s - loss: 0.7588 - acc: 0.700 - 0s 3ms/step - loss: 0.7314 - acc: 0.7273 - val_loss: 1.3533 - val_acc: 0.3051\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - ETA: 0s - loss: 0.7077 - acc: 0.733 - ETA: 0s - loss: 0.6791 - acc: 0.777 - ETA: 0s - loss: 0.7505 - acc: 0.716 - ETA: 0s - loss: 0.7448 - acc: 0.706 - 0s 4ms/step - loss: 0.7406 - acc: 0.7045 - val_loss: 1.3224 - val_acc: 0.3729\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.6980 - acc: 0.666 - ETA: 0s - loss: 0.6934 - acc: 0.633 - ETA: 0s - loss: 0.6055 - acc: 0.733 - 0s 3ms/step - loss: 0.5868 - acc: 0.7727 - val_loss: 1.4343 - val_acc: 0.3729\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.4958 - acc: 0.866 - ETA: 0s - loss: 0.5178 - acc: 0.800 - ETA: 0s - loss: 0.5224 - acc: 0.800 - ETA: 0s - loss: 0.5286 - acc: 0.800 - 0s 3ms/step - loss: 0.5464 - acc: 0.7727 - val_loss: 1.4926 - val_acc: 0.2881\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.5689 - acc: 0.800 - ETA: 0s - loss: 0.3946 - acc: 0.888 - ETA: 0s - loss: 0.4856 - acc: 0.826 - 0s 3ms/step - loss: 0.4869 - acc: 0.8182 - val_loss: 1.5902 - val_acc: 0.2712\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.2719 - acc: 0.933 - ETA: 0s - loss: 0.3314 - acc: 0.911 - ETA: 0s - loss: 0.3936 - acc: 0.866 - 0s 3ms/step - loss: 0.3967 - acc: 0.8750 - val_loss: 1.5174 - val_acc: 0.3559\n",
      "Epoch 36/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.3167 - acc: 0.933 - ETA: 0s - loss: 0.2825 - acc: 0.911 - ETA: 0s - loss: 0.2830 - acc: 0.920 - 0s 3ms/step - loss: 0.3221 - acc: 0.8977 - val_loss: 2.2044 - val_acc: 0.3390\n",
      "Epoch 37/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.5177 - acc: 0.800 - ETA: 0s - loss: 0.3585 - acc: 0.888 - ETA: 0s - loss: 0.3856 - acc: 0.906 - 0s 3ms/step - loss: 0.3640 - acc: 0.9091 - val_loss: 1.8191 - val_acc: 0.3051\n",
      "Epoch 38/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.1916 - acc: 0.933 - ETA: 0s - loss: 0.2638 - acc: 0.933 - ETA: 0s - loss: 0.2590 - acc: 0.946 - 0s 3ms/step - loss: 0.2673 - acc: 0.9432 - val_loss: 1.9979 - val_acc: 0.2881\n",
      "Epoch 39/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.3056 - acc: 0.866 - ETA: 0s - loss: 0.1899 - acc: 0.955 - ETA: 0s - loss: 0.2352 - acc: 0.906 - 0s 3ms/step - loss: 0.2275 - acc: 0.8977 - val_loss: 1.9996 - val_acc: 0.2034\n",
      "Epoch 40/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.2445 - acc: 0.933 - ETA: 0s - loss: 0.2752 - acc: 0.888 - ETA: 0s - loss: 0.2647 - acc: 0.920 - 0s 3ms/step - loss: 0.2696 - acc: 0.9205 - val_loss: 1.7109 - val_acc: 0.3390\n",
      "Epoch 41/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.1657 - acc: 1.000 - ETA: 0s - loss: 0.1738 - acc: 1.000 - ETA: 0s - loss: 0.1490 - acc: 1.000 - ETA: 0s - loss: 0.1858 - acc: 0.973 - 0s 3ms/step - loss: 0.2043 - acc: 0.9545 - val_loss: 1.9103 - val_acc: 0.3051\n",
      "Epoch 42/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.1446 - acc: 1.000 - ETA: 0s - loss: 0.1008 - acc: 1.000 - ETA: 0s - loss: 0.1029 - acc: 0.986 - 0s 3ms/step - loss: 0.1236 - acc: 0.9773 - val_loss: 2.2306 - val_acc: 0.3051\n",
      "Epoch 43/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.1629 - acc: 1.000 - ETA: 0s - loss: 0.1174 - acc: 0.977 - ETA: 0s - loss: 0.0887 - acc: 0.986 - 0s 3ms/step - loss: 0.0932 - acc: 0.9773 - val_loss: 2.4469 - val_acc: 0.2712\n",
      "Epoch 44/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.2734 - acc: 0.866 - ETA: 0s - loss: 0.2256 - acc: 0.888 - ETA: 0s - loss: 0.1902 - acc: 0.906 - 0s 3ms/step - loss: 0.1670 - acc: 0.9205 - val_loss: 2.3576 - val_acc: 0.2881\n",
      "Epoch 45/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.1704 - acc: 0.933 - ETA: 0s - loss: 0.1172 - acc: 0.966 - ETA: 0s - loss: 0.2585 - acc: 0.955 - ETA: 0s - loss: 0.2659 - acc: 0.906 - 0s 3ms/step - loss: 0.2406 - acc: 0.9205 - val_loss: 2.3699 - val_acc: 0.3051\n",
      "Epoch 46/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0487 - acc: 1.000 - ETA: 0s - loss: 0.1186 - acc: 0.955 - ETA: 0s - loss: 0.1409 - acc: 0.946 - 0s 3ms/step - loss: 0.1314 - acc: 0.9545 - val_loss: 2.0919 - val_acc: 0.3390\n",
      "Epoch 47/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0994 - acc: 1.000 - ETA: 0s - loss: 0.0627 - acc: 1.000 - ETA: 0s - loss: 0.0488 - acc: 1.000 - ETA: 0s - loss: 0.0442 - acc: 1.000 - 0s 4ms/step - loss: 0.0432 - acc: 1.0000 - val_loss: 2.3161 - val_acc: 0.3220\n",
      "Epoch 48/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0991 - acc: 0.933 - ETA: 0s - loss: 0.1581 - acc: 0.911 - ETA: 0s - loss: 0.1607 - acc: 0.916 - ETA: 0s - loss: 0.1389 - acc: 0.933 - 0s 5ms/step - loss: 0.1317 - acc: 0.9432 - val_loss: 2.2681 - val_acc: 0.3559\n",
      "Epoch 49/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0471 - acc: 1.000 - ETA: 0s - loss: 0.0205 - acc: 1.000 - ETA: 0s - loss: 0.0382 - acc: 1.000 - 0s 3ms/step - loss: 0.0390 - acc: 1.0000 - val_loss: 2.3935 - val_acc: 0.2881\n",
      "Epoch 50/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.1334 - acc: 0.933 - ETA: 0s - loss: 0.0772 - acc: 0.966 - ETA: 0s - loss: 0.0741 - acc: 0.977 - ETA: 0s - loss: 0.0582 - acc: 0.983 - 0s 4ms/step - loss: 0.0427 - acc: 0.9886 - val_loss: 2.5070 - val_acc: 0.3220\n",
      "Epoch 51/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0221 - acc: 1.000 - ETA: 0s - loss: 0.0242 - acc: 1.000 - ETA: 0s - loss: 0.0331 - acc: 1.000 - ETA: 0s - loss: 0.0531 - acc: 0.983 - ETA: 0s - loss: 0.0971 - acc: 0.973 - 0s 4ms/step - loss: 0.0976 - acc: 0.9773 - val_loss: 2.5153 - val_acc: 0.3729\n",
      "Epoch 52/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0118 - acc: 1.000 - ETA: 0s - loss: 0.0399 - acc: 1.000 - ETA: 0s - loss: 0.0252 - acc: 1.000 - 0s 4ms/step - loss: 0.0352 - acc: 1.0000 - val_loss: 2.6733 - val_acc: 0.3220\n",
      "Epoch 53/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0473 - acc: 1.000 - ETA: 0s - loss: 0.0384 - acc: 1.000 - ETA: 0s - loss: 0.0366 - acc: 1.000 - ETA: 0s - loss: 0.0374 - acc: 1.000 - 0s 4ms/step - loss: 0.0373 - acc: 1.0000 - val_loss: 2.6280 - val_acc: 0.3220\n",
      "Epoch 54/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0702 - acc: 1.000 - ETA: 0s - loss: 0.0669 - acc: 0.977 - ETA: 0s - loss: 0.0455 - acc: 0.986 - 0s 3ms/step - loss: 0.0414 - acc: 0.9886 - val_loss: 2.5910 - val_acc: 0.3220\n",
      "Epoch 55/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0180 - acc: 1.000 - ETA: 0s - loss: 0.0225 - acc: 1.000 - ETA: 0s - loss: 0.0193 - acc: 1.000 - 0s 3ms/step - loss: 0.0180 - acc: 1.0000 - val_loss: 2.8026 - val_acc: 0.2881\n",
      "Epoch 56/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0176 - acc: 1.000 - ETA: 0s - loss: 0.0257 - acc: 1.000 - ETA: 0s - loss: 0.0201 - acc: 1.000 - 0s 3ms/step - loss: 0.0178 - acc: 1.0000 - val_loss: 2.7806 - val_acc: 0.3390\n",
      "Epoch 57/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0046 - acc: 1.000 - ETA: 0s - loss: 0.0035 - acc: 1.000 - ETA: 0s - loss: 0.0055 - acc: 1.000 - 0s 3ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.8653 - val_acc: 0.3220\n",
      "Epoch 58/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0963 - acc: 0.933 - ETA: 0s - loss: 0.0481 - acc: 0.977 - ETA: 0s - loss: 0.0368 - acc: 0.986 - 0s 3ms/step - loss: 0.0325 - acc: 0.9886 - val_loss: 3.1058 - val_acc: 0.2542\n",
      "Epoch 59/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0083 - acc: 1.000 - ETA: 0s - loss: 0.0080 - acc: 1.000 - ETA: 0s - loss: 0.0120 - acc: 1.000 - 0s 3ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 3.0559 - val_acc: 0.3390\n",
      "Epoch 60/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.1140 - acc: 0.933 - ETA: 0s - loss: 0.0440 - acc: 0.977 - ETA: 0s - loss: 0.0275 - acc: 0.986 - 0s 3ms/step - loss: 0.0236 - acc: 0.9886 - val_loss: 3.0091 - val_acc: 0.3220\n",
      "Epoch 61/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0207 - acc: 1.000 - ETA: 0s - loss: 0.0160 - acc: 1.000 - ETA: 0s - loss: 0.0193 - acc: 1.000 - 0s 3ms/step - loss: 0.0166 - acc: 1.0000 - val_loss: 2.9975 - val_acc: 0.3559\n",
      "Epoch 62/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0238 - acc: 1.000 - ETA: 0s - loss: 0.0141 - acc: 1.000 - ETA: 0s - loss: 0.0100 - acc: 1.000 - 0s 3ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 3.0261 - val_acc: 0.3220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0108 - acc: 1.000 - ETA: 0s - loss: 0.0055 - acc: 1.000 - ETA: 0s - loss: 0.0081 - acc: 1.000 - 0s 3ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 3.1387 - val_acc: 0.3390\n",
      "Epoch 64/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0190 - acc: 1.000 - ETA: 0s - loss: 0.0120 - acc: 1.000 - ETA: 0s - loss: 0.0090 - acc: 1.000 - 0s 3ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 3.0666 - val_acc: 0.3220\n",
      "Epoch 65/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0098 - acc: 1.000 - ETA: 0s - loss: 0.0266 - acc: 1.000 - ETA: 0s - loss: 0.0286 - acc: 0.986 - 0s 3ms/step - loss: 0.0247 - acc: 0.9886 - val_loss: 3.1564 - val_acc: 0.3390\n",
      "Epoch 66/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0109 - acc: 1.000 - ETA: 0s - loss: 0.0195 - acc: 1.000 - ETA: 0s - loss: 0.0143 - acc: 1.000 - 0s 3ms/step - loss: 0.0134 - acc: 1.0000 - val_loss: 3.3608 - val_acc: 0.3220\n",
      "Epoch 67/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0121 - acc: 1.000 - ETA: 0s - loss: 0.0127 - acc: 1.000 - ETA: 0s - loss: 0.0269 - acc: 0.986 - 0s 3ms/step - loss: 0.0282 - acc: 0.9886 - val_loss: 3.0662 - val_acc: 0.2881\n",
      "Epoch 68/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0268 - acc: 1.000 - ETA: 0s - loss: 0.0242 - acc: 1.000 - ETA: 0s - loss: 0.0201 - acc: 1.000 - 0s 3ms/step - loss: 0.0196 - acc: 1.0000 - val_loss: 3.1123 - val_acc: 0.2881\n",
      "Epoch 69/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0367 - acc: 1.000 - ETA: 0s - loss: 0.0682 - acc: 0.977 - ETA: 0s - loss: 0.0455 - acc: 0.986 - 0s 3ms/step - loss: 0.0390 - acc: 0.9886 - val_loss: 3.2737 - val_acc: 0.2881\n",
      "Epoch 70/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0088 - acc: 1.000 - ETA: 0s - loss: 0.0536 - acc: 0.977 - ETA: 0s - loss: 0.0367 - acc: 0.986 - 0s 3ms/step - loss: 0.0315 - acc: 0.9886 - val_loss: 3.2335 - val_acc: 0.3220\n",
      "Epoch 71/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0746 - acc: 0.933 - ETA: 0s - loss: 0.0306 - acc: 0.977 - ETA: 0s - loss: 0.0227 - acc: 0.986 - 0s 3ms/step - loss: 0.0195 - acc: 0.9886 - val_loss: 3.2062 - val_acc: 0.3051\n",
      "Epoch 72/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 5.0325e-04 - acc: 1.000 - ETA: 0s - loss: 0.0029 - acc: 1.0000    - ETA: 0s - loss: 0.0059 - acc: 1.000 - 0s 3ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 3.3464 - val_acc: 0.2881\n",
      "Epoch 73/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0067 - acc: 1.000 - ETA: 0s - loss: 0.0085 - acc: 1.000 - ETA: 0s - loss: 0.0079 - acc: 1.000 - 0s 3ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 3.5084 - val_acc: 0.3559\n",
      "Epoch 74/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0604 - acc: 0.933 - ETA: 0s - loss: 0.0318 - acc: 0.977 - ETA: 0s - loss: 0.0284 - acc: 0.986 - 0s 3ms/step - loss: 0.0266 - acc: 0.9886 - val_loss: 3.7264 - val_acc: 0.2881\n",
      "Epoch 75/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0036 - acc: 1.000 - ETA: 0s - loss: 0.0428 - acc: 0.977 - ETA: 0s - loss: 0.0329 - acc: 0.986 - 0s 3ms/step - loss: 0.0318 - acc: 0.9886 - val_loss: 3.1461 - val_acc: 0.3051\n",
      "Epoch 76/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 2.1320e-04 - acc: 1.000 - ETA: 0s - loss: 0.0044 - acc: 1.0000    - ETA: 0s - loss: 0.0329 - acc: 0.986 - 0s 3ms/step - loss: 0.0283 - acc: 0.9886 - val_loss: 3.1075 - val_acc: 0.3390\n",
      "Epoch 77/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0064 - acc: 1.000 - ETA: 0s - loss: 0.0049 - acc: 1.000 - ETA: 0s - loss: 0.0098 - acc: 1.000 - 0s 3ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 3.3709 - val_acc: 0.3729\n",
      "Epoch 78/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0118 - acc: 1.000 - ETA: 0s - loss: 0.0072 - acc: 1.000 - ETA: 0s - loss: 0.0148 - acc: 1.000 - 0s 3ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 3.6167 - val_acc: 0.2881\n",
      "Epoch 79/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0142 - acc: 1.000 - ETA: 0s - loss: 0.0259 - acc: 0.977 - ETA: 0s - loss: 0.0342 - acc: 0.986 - 0s 3ms/step - loss: 0.0327 - acc: 0.9886 - val_loss: 3.8791 - val_acc: 0.3051\n",
      "Epoch 80/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 4.7092e-04 - acc: 1.000 - ETA: 0s - loss: 0.0163 - acc: 1.0000    - ETA: 0s - loss: 0.0213 - acc: 1.000 - 0s 3ms/step - loss: 0.0226 - acc: 1.0000 - val_loss: 3.6329 - val_acc: 0.3729\n",
      "Epoch 81/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0476 - acc: 1.000 - ETA: 0s - loss: 0.0176 - acc: 1.000 - ETA: 0s - loss: 0.0137 - acc: 1.000 - ETA: 0s - loss: 0.0127 - acc: 1.000 - 0s 3ms/step - loss: 0.0326 - acc: 0.9886 - val_loss: 4.1739 - val_acc: 0.3390\n",
      "Epoch 82/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.1033 - acc: 0.933 - ETA: 0s - loss: 0.0424 - acc: 0.977 - ETA: 0s - loss: 0.0268 - acc: 0.986 - 0s 3ms/step - loss: 0.0270 - acc: 0.9886 - val_loss: 3.5693 - val_acc: 0.2712\n",
      "Epoch 83/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0046 - acc: 1.000 - ETA: 0s - loss: 0.0198 - acc: 1.000 - ETA: 0s - loss: 0.0129 - acc: 1.000 - 0s 3ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 3.6745 - val_acc: 0.2881\n",
      "Epoch 84/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0382 - acc: 1.000 - ETA: 0s - loss: 0.0326 - acc: 1.000 - ETA: 0s - loss: 0.0287 - acc: 1.000 - 0s 3ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 3.5112 - val_acc: 0.3729\n",
      "Epoch 85/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0106 - acc: 1.000 - ETA: 0s - loss: 0.0074 - acc: 1.000 - ETA: 0s - loss: 0.0071 - acc: 1.000 - 0s 3ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 3.6605 - val_acc: 0.3559\n",
      "Epoch 86/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.7764e-04 - acc: 1.000 - ETA: 0s - loss: 0.0085 - acc: 1.0000    - ETA: 0s - loss: 0.0059 - acc: 1.000 - 0s 3ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 3.7438 - val_acc: 0.3898\n",
      "Epoch 87/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0038 - acc: 1.000 - ETA: 0s - loss: 0.0024 - acc: 1.000 - ETA: 0s - loss: 0.0023 - acc: 1.000 - 0s 3ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 3.8375 - val_acc: 0.3559\n",
      "Epoch 88/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 3.8838e-04 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.0000    - ETA: 0s - loss: 0.0016 - acc: 1.000 - 0s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 3.9107 - val_acc: 0.3390\n",
      "Epoch 89/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.1007 - acc: 0.977 - ETA: 0s - loss: 0.0607 - acc: 0.986 - 0s 3ms/step - loss: 0.0563 - acc: 0.9886 - val_loss: 4.0751 - val_acc: 0.3390\n",
      "Epoch 90/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0132 - acc: 1.000 - ETA: 0s - loss: 0.0090 - acc: 1.000 - ETA: 0s - loss: 0.0096 - acc: 1.000 - 0s 3ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 4.0210 - val_acc: 0.2712\n",
      "Epoch 91/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 7.0766e-04 - acc: 1.000 - ETA: 0s - loss: 0.0039 - acc: 1.0000    - ETA: 0s - loss: 0.0029 - acc: 1.000 - 0s 3ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 3.9894 - val_acc: 0.2881\n",
      "Epoch 92/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 7.4410e-04 - acc: 1.000 - ETA: 0s - loss: 7.1094e-04 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.0000    - 0s 3ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 4.0536 - val_acc: 0.2881\n",
      "Epoch 93/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0032 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0048 - acc: 1.000 - 0s 3ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 4.1502 - val_acc: 0.3559\n",
      "Epoch 94/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 5.3116e-04 - acc: 1.000 - ETA: 0s - loss: 0.0024 - acc: 1.0000    - ETA: 0s - loss: 0.0027 - acc: 1.000 - 0s 3ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 4.2464 - val_acc: 0.3051\n",
      "Epoch 95/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0034 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0065 - acc: 1.000 - 0s 3ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 4.5457 - val_acc: 0.2712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 2.6654e-04 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.0000    - ETA: 0s - loss: 0.0079 - acc: 1.000 - 0s 3ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 4.5608 - val_acc: 0.2712\n",
      "Epoch 97/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0129 - acc: 1.000 - ETA: 0s - loss: 0.0046 - acc: 1.000 - ETA: 0s - loss: 0.0034 - acc: 1.000 - 0s 3ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 4.4696 - val_acc: 0.3390\n",
      "Epoch 98/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0068 - acc: 1.000 - ETA: 0s - loss: 0.0054 - acc: 1.000 - ETA: 0s - loss: 0.0049 - acc: 1.000 - 0s 3ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 4.3428 - val_acc: 0.3051\n",
      "Epoch 99/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0340 - acc: 1.000 - ETA: 0s - loss: 0.0177 - acc: 1.000 - ETA: 0s - loss: 0.0092 - acc: 1.000 - 0s 4ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 4.4416 - val_acc: 0.2881\n",
      "Epoch 100/100\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 9.0988e-04 - acc: 1.000 - 0s 4ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 4.2676 - val_acc: 0.3220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b523d15390>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(predict('./luke_02_4.wav', model=model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-3702719fe721>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
